# Generative AI with Large Language Models (LLMs) Course, offered by DeepLearning.ai
Last update: 2024-01-03

## Course Description
This course provides an in-depth exploration into the world of generative AI, focusing on Large Language Models (LLMs). 

### Course Modules
The course is divided into three comprehensive modules:

1. **Fundamentals of Generative AI and LLMs**: Understanding the core concepts and lifecycle of LLM-based generative AI, including data gathering, model selection, performance evaluation, and deployment.
2. **Transformer Architecture and Training**: Detailed exploration of the transformer architecture that powers LLMs, their training processes, and the fine-tuning techniques for adapting LLMs to various use cases.
3. **Optimization and Deployment**: Techniques for optimizing LLMs across dataset size, compute budget, and inference requirements, along with state-of-the-art methods for training, tuning, and deploying these models.

## Acknowledgments
The course note is completely based on the course [Generative AI with Large Language Models (LLMs)](https://www.coursera.org/learn/generative-ai-with-llms?) by DeepLearning.AI. The content reflects the key learning points and modules as outlined in the course at the time of its launch. It is intended to serve as a concise reference of the course to easily review later on.

## What's Next?

After taking this course, you can check out other free and extremely useful short courses offered DeepLearning.ai [here](https://www.deeplearning.ai/short-courses/)
